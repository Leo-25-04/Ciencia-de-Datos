{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Primer examen de PPCD, tiempo de realización 2 horas"
      ],
      "metadata": {
        "id": "nYre7rDlGu46"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESHYk74RGdNV"
      },
      "outputs": [],
      "source": [
        "NAME = \"Leonardo Negrete Mancera\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lJZp5-KXGiQg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Usando el conjunto de datos Iris de sklearn, realiza las siguientes actividades:** (15p)\n",
        "\n",
        "**a) Con ayuda de un algoritmo de selección conserva las dos características más importantes para el conjunto utilizando un perceptrón ($\\eta=0.1$ y replicabilidad 42) como estimador y conserva esas características en un arreglo de numpy para usarlo posteriormente**"
      ],
      "metadata": {
        "id": "QtnzlNwNGpgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "#print(X)\n",
        "y = iris.target\n",
        "\n",
        "perceptron = Perceptron(eta0=0.1, random_state=42)\n",
        "\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "selector = SelectFromModel(perceptron, max_features=2, prefit=True)\n",
        "\n",
        "elegidas = selector.transform(X)\n",
        "\n",
        "print(\"Características seleccionadas (shape):\", elegidas.shape)\n",
        "\n",
        "#elegidas = ... # características de la selección secuencial\n",
        "# X = ... # arreglo con las características de la selección secuencial\n",
        "print(elegidas)"
      ],
      "metadata": {
        "id": "J9VzVzfMGqiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Aplica el clasificador determinista a priori visto en clase para obtener las funciones discrimantes correspondientes a las tres clases con las características del inciso (a)**"
      ],
      "metadata": {
        "id": "qubldZYxHF4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sympy import Matrix, symbols, simplify, init_printing\n",
        "\n",
        "\n",
        "init_printing()\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "perceptron = Perceptron(eta0=0.1, random_state=42)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "selector = SelectFromModel(perceptron, max_features=2, prefit=True)\n",
        "X_selected = selector.transform(X)\n",
        "print(X_selected)\n",
        "\n",
        "X_class_0 = X_selected[y == 0].T  # Setosa\n",
        "X_class_1 = X_selected[y == 1].T  # Versicolor\n",
        "X_class_2 = X_selected[y == 2].T  # Virginica\n",
        "\n",
        "\n",
        "def clasif_e(samples):\n",
        "    X = Matrix([symbols(f'x{i}') for i in range(samples[0].shape[0])])\n",
        "    fds = []\n",
        "    for s in samples:\n",
        "        m = Matrix(np.mean(s, axis=1))\n",
        "        fd = simplify(X.T * m - (m.T * m) / 2)\n",
        "        fds.append(fd)\n",
        "    return fds\n",
        "\n",
        "fds = clasif_e([X_class_0, X_class_1, X_class_2])\n",
        "\n",
        "for i, fd in enumerate(fds):\n",
        "    print(f\"Función discriminante para clase {i}:\")\n",
        "    display(fd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "66NdaV3KG_0o",
        "outputId": "7765f3ff-d175-42c8-f8e2-0a06535ada7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.5 0.2]\n",
            " [3.  0.2]\n",
            " [3.2 0.2]\n",
            " [3.1 0.2]\n",
            " [3.6 0.2]\n",
            " [3.9 0.4]\n",
            " [3.4 0.3]\n",
            " [3.4 0.2]\n",
            " [2.9 0.2]\n",
            " [3.1 0.1]\n",
            " [3.7 0.2]\n",
            " [3.4 0.2]\n",
            " [3.  0.1]\n",
            " [3.  0.1]\n",
            " [4.  0.2]\n",
            " [4.4 0.4]\n",
            " [3.9 0.4]\n",
            " [3.5 0.3]\n",
            " [3.8 0.3]\n",
            " [3.8 0.3]\n",
            " [3.4 0.2]\n",
            " [3.7 0.4]\n",
            " [3.6 0.2]\n",
            " [3.3 0.5]\n",
            " [3.4 0.2]\n",
            " [3.  0.2]\n",
            " [3.4 0.4]\n",
            " [3.5 0.2]\n",
            " [3.4 0.2]\n",
            " [3.2 0.2]\n",
            " [3.1 0.2]\n",
            " [3.4 0.4]\n",
            " [4.1 0.1]\n",
            " [4.2 0.2]\n",
            " [3.1 0.2]\n",
            " [3.2 0.2]\n",
            " [3.5 0.2]\n",
            " [3.6 0.1]\n",
            " [3.  0.2]\n",
            " [3.4 0.2]\n",
            " [3.5 0.3]\n",
            " [2.3 0.3]\n",
            " [3.2 0.2]\n",
            " [3.5 0.6]\n",
            " [3.8 0.4]\n",
            " [3.  0.3]\n",
            " [3.8 0.2]\n",
            " [3.2 0.2]\n",
            " [3.7 0.2]\n",
            " [3.3 0.2]\n",
            " [3.2 1.4]\n",
            " [3.2 1.5]\n",
            " [3.1 1.5]\n",
            " [2.3 1.3]\n",
            " [2.8 1.5]\n",
            " [2.8 1.3]\n",
            " [3.3 1.6]\n",
            " [2.4 1. ]\n",
            " [2.9 1.3]\n",
            " [2.7 1.4]\n",
            " [2.  1. ]\n",
            " [3.  1.5]\n",
            " [2.2 1. ]\n",
            " [2.9 1.4]\n",
            " [2.9 1.3]\n",
            " [3.1 1.4]\n",
            " [3.  1.5]\n",
            " [2.7 1. ]\n",
            " [2.2 1.5]\n",
            " [2.5 1.1]\n",
            " [3.2 1.8]\n",
            " [2.8 1.3]\n",
            " [2.5 1.5]\n",
            " [2.8 1.2]\n",
            " [2.9 1.3]\n",
            " [3.  1.4]\n",
            " [2.8 1.4]\n",
            " [3.  1.7]\n",
            " [2.9 1.5]\n",
            " [2.6 1. ]\n",
            " [2.4 1.1]\n",
            " [2.4 1. ]\n",
            " [2.7 1.2]\n",
            " [2.7 1.6]\n",
            " [3.  1.5]\n",
            " [3.4 1.6]\n",
            " [3.1 1.5]\n",
            " [2.3 1.3]\n",
            " [3.  1.3]\n",
            " [2.5 1.3]\n",
            " [2.6 1.2]\n",
            " [3.  1.4]\n",
            " [2.6 1.2]\n",
            " [2.3 1. ]\n",
            " [2.7 1.3]\n",
            " [3.  1.2]\n",
            " [2.9 1.3]\n",
            " [2.9 1.3]\n",
            " [2.5 1.1]\n",
            " [2.8 1.3]\n",
            " [3.3 2.5]\n",
            " [2.7 1.9]\n",
            " [3.  2.1]\n",
            " [2.9 1.8]\n",
            " [3.  2.2]\n",
            " [3.  2.1]\n",
            " [2.5 1.7]\n",
            " [2.9 1.8]\n",
            " [2.5 1.8]\n",
            " [3.6 2.5]\n",
            " [3.2 2. ]\n",
            " [2.7 1.9]\n",
            " [3.  2.1]\n",
            " [2.5 2. ]\n",
            " [2.8 2.4]\n",
            " [3.2 2.3]\n",
            " [3.  1.8]\n",
            " [3.8 2.2]\n",
            " [2.6 2.3]\n",
            " [2.2 1.5]\n",
            " [3.2 2.3]\n",
            " [2.8 2. ]\n",
            " [2.8 2. ]\n",
            " [2.7 1.8]\n",
            " [3.3 2.1]\n",
            " [3.2 1.8]\n",
            " [2.8 1.8]\n",
            " [3.  1.8]\n",
            " [2.8 2.1]\n",
            " [3.  1.6]\n",
            " [2.8 1.9]\n",
            " [3.8 2. ]\n",
            " [2.8 2.2]\n",
            " [2.8 1.5]\n",
            " [2.6 1.4]\n",
            " [3.  2.3]\n",
            " [3.4 2.4]\n",
            " [3.1 1.8]\n",
            " [3.  1.8]\n",
            " [3.1 2.1]\n",
            " [3.1 2.4]\n",
            " [3.1 2.3]\n",
            " [2.7 1.9]\n",
            " [3.2 2.3]\n",
            " [3.3 2.5]\n",
            " [3.  2.3]\n",
            " [2.5 1.9]\n",
            " [3.  2. ]\n",
            " [3.4 2.3]\n",
            " [3.  1.8]]\n",
            "Función discriminante para clase 0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[3.428⋅x₀ + 0.246⋅x₁ - 5.90585]"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}3.428 x_{0} + 0.246 x_{1} - 5.90585\\end{matrix}\\right]$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función discriminante para clase 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[2.77⋅x₀ + 1.326⋅x₁ - 4.715588]"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}2.77 x_{0} + 1.326 x_{1} - 4.715588\\end{matrix}\\right]$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función discriminante para clase 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[2.974⋅x₀ + 2.026⋅x₁ - 6.474676]"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}2.974 x_{0} + 2.026 x_{1} - 6.474676\\end{matrix}\\right]$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) Aplica el clasificador probabilista a priori visto en clase para obtener las funciones discrimantes correspondientes a las tres clases con las características obtenidas en el inciso (a)**"
      ],
      "metadata": {
        "id": "oO1WkyFvHMl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sympy import Matrix, symbols, simplify, init_printing\n",
        "\n",
        "\n",
        "init_printing()\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "perceptron = Perceptron(eta0=0.1, random_state=42)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "selector = SelectFromModel(perceptron, max_features=2, prefit=True)\n",
        "X_selected = selector.transform(X)\n",
        "\n",
        "\n",
        "X_class_0 = X_selected[y == 0].T  # Setosa\n",
        "X_class_1 = X_selected[y == 1].T  # Versicolor\n",
        "X_class_2 = X_selected[y == 2].T  # Virginica\n",
        "\n",
        "\n",
        "\n",
        "#SYMPY => Simbolic python\n",
        "from sympy import Matrix, symbols, simplify, log\n",
        "\n",
        "def clasif_m(samples):\n",
        "    #Matriz de variables predictorias\n",
        "    X = Matrix( [ symbols( \"x\"+str(i) ) for i in range(samples[0].shape[0])  ] )\n",
        "    #print(x)\n",
        "    fds=[]\n",
        "    for s in  samples:\n",
        "        m = Matrix(np.mean(s,axis=1))\n",
        "        mcov = np.cov(s,bias=True)\n",
        "        mci = Matrix(mcov).inv()\n",
        "        print(\"media: \\n\",m,\"cov: \\n\", mcov, \"Matriz Cov Invertido: \\n\", mci)\n",
        "        fds.append( simplify( -.5*(X.T*mci*X) + X.T*mci*m -.5*(m.T*mci*m) -Matrix([.5*(log (mci.det()))]) ) )\n",
        "    return fds\n",
        "\n",
        "\n",
        "for i, fd in enumerate(fds):\n",
        "    print(f\"Función discriminante para clase {i}:\")\n",
        "    display(fd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "_onHQ_SaHQY_",
        "outputId": "01dde6aa-81ac-4169-b6ea-9aa481c21fcc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función discriminante para clase 0:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[3.428⋅x₀ + 0.246⋅x₁ - 5.90585]"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}3.428 x_{0} + 0.246 x_{1} - 5.90585\\end{matrix}\\right]$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función discriminante para clase 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[2.77⋅x₀ + 1.326⋅x₁ - 4.715588]"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}2.77 x_{0} + 1.326 x_{1} - 4.715588\\end{matrix}\\right]$"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función discriminante para clase 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[2.974⋅x₀ + 2.026⋅x₁ - 6.474676]"
            ],
            "text/latex": "$\\displaystyle \\left[\\begin{matrix}2.974 x_{0} + 2.026 x_{1} - 6.474676\\end{matrix}\\right]$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Con la versión propia del Perceptrón escrita en clase ($\\eta=0.1$, replicabilidad nula) simula la clasificación multiclase sobre el conjunto Iris reducido con la selección secuencial** (15p)"
      ],
      "metadata": {
        "id": "A2xWWK4MHZpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron as SKPerceptron\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "selector_model = SKPerceptron(eta0=0.1, random_state=42)\n",
        "selector_model.fit(X, y)\n",
        "selector = SelectFromModel(selector_model, max_features=2, prefit=True)\n",
        "X_reduced = selector.transform(X)\n",
        "\n",
        "\n",
        "class Perceptron():\n",
        "    def __init__(self, eta=0.01, n_iter=50, random_state=None):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self ,X ,y ):\n",
        "        rgen = np.random.RandomState(self.random_state)\n",
        "        if self.random_state is None:\n",
        "            self.w_ = np.zeros(1 + X.shape[1])\n",
        "        else:\n",
        "            self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "        self.errors_ = []\n",
        "        for _ in range(self.n_iter):\n",
        "            errors = 0\n",
        "            for xi, yi in zip(X, y):\n",
        "                update = self.eta * (yi - self.predict(xi))\n",
        "                self.w_[0] += update\n",
        "                self.w_[1:] += update * xi\n",
        "                errors += int(update != 0.0)\n",
        "            self.errors_.append(errors)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
        "\n",
        "perceptrons = []\n",
        "pesos = []\n",
        "\n",
        "for clase in [0, 1, 2]:\n",
        "    y_binary = np.where(y == clase, 1, -1)  # Clase actual como 1, resto como -1\n",
        "    p = Perceptron(eta=0.1, n_iter=50, random_state=None)\n",
        "    p.fit(X_reduced, y_binary)\n",
        "    perceptrons.append(p)\n",
        "    pesos.append(p.w_)\n",
        "\n",
        "\n",
        "pesos1, pesos2, pesos3 = pesos\n",
        "\n",
        "print(\"Pesos clase 0 (Setosa):\", pesos1)\n",
        "print(\"Pesos clase 1 (Versicolor):\", pesos2)\n",
        "print(\"Pesos clase 2 (Virginica):\", pesos3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jTlpomOHaxE",
        "outputId": "525a44ed-bcbd-4d1d-88ca-cb2f75086591"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos clase 0 (Setosa): [ 0.    0.06 -0.24]\n",
            "Pesos clase 1 (Versicolor): [ 0.    0.06 -1.18]\n",
            "Pesos clase 2 (Virginica): [-1.  -2.4  5.4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Realiza una una función *desde cero* que reciba un *DataFrame*, el nombre de la columna de la que se obtendrán las categorías y el nombre de la columna objetivo para determinar el *peso de la evidencia* de cada categoría; tu función debe devolver una lista de parejas $[cat, woe\\_cat]$** (15p)"
      ],
      "metadata": {
        "id": "xRUAZnSpHi96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def woe(df, col, col_obj):\n",
        "    \"\"\"\n",
        "    Parametros:\n",
        "        df (pd.DataFrame): DataFrame que contiene los datos.\n",
        "        col (str): Nombre de la columna categórica.\n",
        "        col_obj (str): Nombre de la columna objetivo binaria (0 y 1).\n",
        "\n",
        "    Atributos:\n",
        "        List of [categoria, woe_valor]\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    total_good = (df[col_obj] == 1).sum()\n",
        "    total_bad = (df[col_obj] == 0).sum()\n",
        "\n",
        "    grouped = df.groupby(col)[col_obj].agg(['count', 'sum'])\n",
        "    grouped.columns = ['total', 'good']\n",
        "    grouped['bad'] = grouped['total'] - grouped['good']\n",
        "\n",
        "    grouped['dist_good'] = grouped['good'] / total_good\n",
        "    grouped['dist_bad'] = grouped['bad'] / total_bad\n",
        "\n",
        "\n",
        "    grouped['woe'] = np.log(grouped['dist_good'] / grouped['dist_bad']).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    result = grouped['woe'].reset_index().values.tolist()\n",
        "\n",
        "    return result\n",
        "\n",
        "#def woe(df, col, col_obj)"
      ],
      "metadata": {
        "id": "4T8d3IdLHjwu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Importa el conjunto de datos *diabetes_data.csv* y aplica tu función a las columnas *GenHlth*, *Income* y *Education***"
      ],
      "metadata": {
        "id": "7iCPBdW1Hpef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Upload the file if it's not already present\n",
        "# If the file is already uploaded, you might skip this line or run it again to re-upload\n",
        "# If you run it multiple times, it might prompt you to upload again.\n",
        "\n",
        "\n",
        "df = pd.read_csv('diabetes_data.csv')\n",
        "print(df.head(2))\n",
        "\n",
        "woe_genhlth = woe(df, 'GenHlth', 'Diabetes_binary')\n",
        "print(woe_genhlth)\n",
        "woe_income = woe(df, 'Income', 'Diabetes_binary')\n",
        "print(woe_income)\n",
        "woe_education = woe(df, 'Education', 'Diabetes_binary')\n",
        "print(woe_education)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmoX362HHvKa",
        "outputId": "325491ed-d7a7-41a1-effa-f4bcf9780816"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0              1.0     0.0       1.0        1.0  23.0     1.0     0.0   \n",
            "1              0.0     0.0       0.0        1.0  33.0     1.0     0.0   \n",
            "\n",
            "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
            "0                   0.0           1.0     0.0  ...            1.0   \n",
            "1                   0.0           0.0     1.0  ...            1.0   \n",
            "\n",
            "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
            "0          0.0      4.0       0.0       0.0       0.0  0.0  10.0        4.0   \n",
            "1          0.0      3.0       0.0       3.0       1.0  0.0  13.0        5.0   \n",
            "\n",
            "   Income  \n",
            "0     5.0  \n",
            "1     4.0  \n",
            "\n",
            "[2 rows x 22 columns]\n",
            "[[1.0, -1.8390361858146629], [2.0, -0.7619574881085688], [3.0, 0.30375664968025856], [4.0, 1.0070241413245922], [5.0, 1.3130367027292869]]\n",
            "[[1.0, 0.6695131851656101], [2.0, 0.7541424842097451], [3.0, 0.5929274727014505], [4.0, 0.4437170558425892], [5.0, 0.2624188333669962], [6.0, 0.04206771550915592], [7.0, -0.16718158540135064], [8.0, -0.617894745309701]]\n",
            "[[1.0, 0.8839878102848632], [2.0, 0.9257188930402491], [3.0, 0.6750495606706104], [4.0, 0.288858316048258], [5.0, 0.08062931386689516], [6.0, -0.4258025902610316]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Realiza una una función que reciba un *DataFrame* y el nombre de una columna como parámetros; calcule *desde cero* las anomalías con el método de los cuartiles visto en clase y devuelva una lista con los índices de los valores anómalos** (10p)"
      ],
      "metadata": {
        "id": "6jXc4wfrKZsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_anomalias(df, col):\n",
        "\n",
        "\n",
        "\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"La columna '{col}' no existe en el DataFrame.\")\n",
        "\n",
        "\n",
        "    serie = df[col]\n",
        "\n",
        "\n",
        "    q1 = serie.quantile(0.25)\n",
        "    q3 = serie.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "\n",
        "\n",
        "    limite_inferior = q1 - 1.5 * iqr\n",
        "    limite_superior = q3 + 1.5 * iqr\n",
        "\n",
        "\n",
        "    anomalias = serie[(serie < limite_inferior) | (serie > limite_superior)]\n",
        "\n",
        "    return anomalias.index.tolist()\n"
      ],
      "metadata": {
        "id": "S2dBGHHnKbDb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Construye un *DataFrame* con el conjunto de datos *Iris* y aplica tu obtención de anomalías a las 4 columnas**"
      ],
      "metadata": {
        "id": "ktGDj_CjKfUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def detectar_anomalias(df, col):\n",
        "    \"\"\"\n",
        "    Detecta outliers usando el rango intercuartílico (IQR).\n",
        "    Retorna una lista de índices.\n",
        "    \"\"\"\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"La columna '{col}' no existe en el DataFrame.\")\n",
        "\n",
        "    serie = df[col]\n",
        "    Q1 = serie.quantile(0.25)\n",
        "    Q3 = serie.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    limite_inf = Q1 - 1.5 * IQR\n",
        "    limite_sup = Q3 + 1.5 * IQR\n",
        "\n",
        "\n",
        "    anomalias = serie[(serie < limite_inf) | (serie > limite_sup)]\n",
        "\n",
        "    return anomalias.index.tolist()\n",
        "\n",
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "print(\"--- REPORTE DE ANOMALÍAS (OUTLIERS) ---\")\n",
        "\n",
        "anomalias_dict = {}\n",
        "\n",
        "for col in df_iris.columns:\n",
        "    indices_outliers = detectar_anomalias(df_iris, col)\n",
        "    anomalias_dict[col] = indices_outliers\n",
        "\n",
        "    if indices_outliers:\n",
        "        print(f\"  {col}: Se detectaron anomalías en los índices {indices_outliers}\")\n",
        "    else:\n",
        "        print(f\"  {col}: No se detectaron anomalías.\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_iris, orient=\"h\", palette=\"Set2\")\n",
        "plt.title(\"Visualización de Anomalías (Boxplot)\", fontsize=14)\n",
        "plt.xlabel(\"Valor (cm)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "H5X5R3csKfyY",
        "outputId": "db3a9543-a8d1-4c88-c916-e38442a1311b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- REPORTE DE ANOMALÍAS (OUTLIERS) ---\n",
            "  sepal length (cm): No se detectaron anomalías.\n",
            "  sepal width (cm): Se detectaron anomalías en los índices [15, 32, 33, 60]\n",
            "  petal length (cm): No se detectaron anomalías.\n",
            "  petal width (cm): No se detectaron anomalías.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Realiza una implementación de PCA *desde cero* que cumpla con la siguiente cadena de documentación:** (10p)"
      ],
      "metadata": {
        "id": "-AO8YIV_L34F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class PCA_():\n",
        "    \"\"\"\n",
        "    PCA\n",
        "    Parameters\n",
        "    ------------\n",
        "    n_pca: int\n",
        "      Número de componentes a conservar; default = None\n",
        "    Attributes\n",
        "    ------------\n",
        "    var_exp_ : 1d_array\n",
        "      Varianza explicada individual\n",
        "    cum_var_exp_ : 1d_array\n",
        "      Varianza explicada acumulativa\n",
        "    w_ : 2d_array\n",
        "      Matriz de transformación con los vectores propios de las n_pca primeras\n",
        "      componentes ordenadas\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_pca=None):\n",
        "        self.n_pca = n_pca\n",
        "        self.var_exp_ = None\n",
        "        self.cum_var_exp_ = None\n",
        "        self.w_ = None\n",
        "        self.mean_ = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Aprendizaje con PCA\n",
        "        Si n_pca es nulo, aplica el algoritmo y w_ tiene el mismo número de columnas\n",
        "        que el conjunto original; en otro caso w_ tendrá n_pca columnas\n",
        "        Parameters\n",
        "        ------------\n",
        "        X : 2d_array, shape = [n_samples, m_features]\n",
        "          Vectores de entrenamiento con n_samples filas y m_features columnas\n",
        "        \"\"\"\n",
        "\n",
        "        self.mean_ = np.mean(X, axis=0)\n",
        "        X_centered = X - self.mean_\n",
        "\n",
        "\n",
        "        cov_mat = np.cov(X_centered, rowvar=False)\n",
        "\n",
        "\n",
        "        eig_vals, eig_vecs = np.linalg.eigh(cov_mat)\n",
        "\n",
        "\n",
        "        sorted_idx = np.argsort(eig_vals)[::-1]\n",
        "        eig_vals_sorted = eig_vals[sorted_idx]\n",
        "        eig_vecs_sorted = eig_vecs[:, sorted_idx]\n",
        "\n",
        "\n",
        "        total_var = np.sum(eig_vals_sorted)\n",
        "        self.var_exp_ = eig_vals_sorted / total_var\n",
        "        self.cum_var_exp_ = np.cumsum(self.var_exp_)\n",
        "\n",
        "\n",
        "        if self.n_pca is None:\n",
        "            self.w_ = eig_vecs_sorted\n",
        "        else:\n",
        "            self.w_ = eig_vecs_sorted[:, :self.n_pca]\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Transforma el conjunto de entrada\n",
        "        Parameters\n",
        "        ------------\n",
        "        X : 2d_array, shape = [n_samples, m_features]\n",
        "          Vectores de entrenamiento con n_samples filas y m_features columnas\n",
        "        Returns\n",
        "        ------------\n",
        "        2d_array, shape = [n_samples, n_pca]\n",
        "          Vectores de entrada proyectados al nuevo espacio con ayuda de la matriz w_\n",
        "        \"\"\"\n",
        "        X_centered = X - self.mean_\n",
        "        return np.dot(X_centered, self.w_)\n"
      ],
      "metadata": {
        "id": "vPKCPWFYL44y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Aplica PCA (propio) para determinar el número de componentes necesarias para conservar el 80% de la información del conjunto con ayuda de los vaalores que se obtienen al entrenar el objeto pca**"
      ],
      "metadata": {
        "id": "Xz2nBhgbMDpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "\n",
        "\n",
        "pca = PCA_()\n",
        "pca.fit(X)\n",
        "\n",
        "\n",
        "cum_var = pca.cum_var_exp_\n",
        "\n",
        "\n",
        "display(cum_var)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Q7Kkx0abMF3L",
        "outputId": "8c00e0cb-fe35-41c7-9feb-200b15a8b1c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.99809123, 0.99982715, 0.99992211, 0.99997232, 0.99998469,\n",
              "       0.99999315, 0.99999596, 0.99999748, 0.99999861, 0.99999933,\n",
              "       0.99999971, 0.99999992, 1.        ])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Aplica tu versión de PCA para reducir el conjunto al número de componentes que determinaste en el inciso (a); entrena una regresión logística con sus parámetros por omisión y calcula su exactitud**"
      ],
      "metadata": {
        "id": "H7F3rRLSML0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "\n",
        "pca_full = PCA_()\n",
        "pca_full.fit(X)\n",
        "cum_var = pca_full.cum_var_exp_\n",
        "n_components_80 = np.argmax(cum_var >= 0.80) + 1\n",
        "#print(n_components_80)\n",
        "\n",
        "\n",
        "pca_reducido = PCA_(n_pca=n_components_80)\n",
        "pca_reducido.fit(X)\n",
        "X_reducido = pca_reducido.transform(X)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reducido, y, random_state=42, test_size=0.3)\n",
        "\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "lr_score = accuracy_score(y_test, y_pred)\n",
        "print(lr_score)\n",
        "#print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-TJpB9aMMI8",
        "outputId": "2369d837-a7cf-4ab0-cb55-c1e769f998a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7037037037037037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c) Aplica el análisis lineal discriminante (LDA) para reducir el conjunto al mismo número de componentes del inciso (a) o al máximo posible, explica tu resultado**"
      ],
      "metadata": {
        "id": "MyWfFg7AMSXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "lda = LDA(n_components=2)\n",
        "X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "print(\"Forma del conjunto reducido por LDA:\", X_lda.shape)\n",
        "#print(X_lda)\n",
        "print(\"A diferencia de PCA, que es no supervisado y puede conservar el número total de características, LDA es un método supervisado que maximiza la separabilidad entre clases. El número máximo de componentes en LDA está limitado por el número de clases menos uno.En el conjunto Wine hay 3 clases, por lo que el número máximo de componentes LDA es: n_clases−1 = 3−1 = 2. Por lo tanto, aunque en PCA se requerían más componentes para conservar el 80% de la varianza, LDA solo puede reducir el conjunto a 2 componentes que maximizan la separación entre clases.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ja93OsyMS61",
        "outputId": "6e962f98-2765-4ceb-f018-5638ba252c50"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma del conjunto reducido por LDA: (178, 2)\n",
            "A diferencia de PCA, que es no supervisado y puede conservar el número total de características, LDA es un método supervisado que maximiza la separabilidad entre clases. El número máximo de componentes en LDA está limitado por el número de clases menos uno.En el conjunto Wine hay 3 clases, por lo que el número máximo de componentes LDA es: n_clases−1 = 3−1 = 2. Por lo tanto, aunque en PCA se requerían más componentes para conservar el 80% de la varianza, LDA solo puede reducir el conjunto a 2 componentes que maximizan la separación entre clases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d) Aplica PCA (propio) y LDA para reducir a dos componentes; para cada uno entrena una regresión logística con sus parámetros por omisión y calcula su exactitud**\n"
      ],
      "metadata": {
        "id": "-lxEze0cMXLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "\n",
        "pca = PCA_(n_pca=2)\n",
        "pca.fit(X)\n",
        "X_pca = pca.transform(X)\n",
        "\n",
        "\n",
        "lda = LDA(n_components=2)\n",
        "X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "\n",
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "X_train_lda, X_test_lda, _, _ = train_test_split(X_lda, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "clf_pca = LogisticRegression()\n",
        "clf_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = clf_pca.predict(X_test_pca)\n",
        "lr_score_pca = accuracy_score(y_test, y_pred_pca)\n",
        "\n",
        "\n",
        "clf_lda = LogisticRegression()\n",
        "clf_lda.fit(X_train_lda, y_train)\n",
        "y_pred_lda = clf_lda.predict(X_test_lda)\n",
        "lr_score_lda = accuracy_score(y_test, y_pred_lda)\n",
        "\n",
        "display(lr_score_pca, lr_score_lda)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "XV4udUNBM8zl",
        "outputId": "e41117d4-e4dc-48c4-b058-e3d08d86a699"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.6851851851851852"
            ],
            "text/latex": "$\\displaystyle 0.685185185185185$"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1.0"
            ],
            "text/latex": "$\\displaystyle 1.0$"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NngA9f-pNHFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. ¿Qué sucede al utilizar *LDA* sobre el conjunto de medias lunas?** (5p)"
      ],
      "metadata": {
        "id": "RFt2NgtCNC9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Su desempeño es muy pobre porque LDA no puede capturar la estructura no lineal del conjunto y al proyectar los datos en un espacio lineal, LDA aplasta la forma curva de las lunas, mezclando las clases, y eso reduce significativamente la capacidad de discriminación."
      ],
      "metadata": {
        "id": "YtPXFz0qNFcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Implementa *desde cero* KernelPCA con la siguiente función de Kernel:** (20p)\n",
        "$$\n",
        "k(x^{(i)}, x^{(j)}) = \\sum_{p=0}^k (c \\times x^{(i)} \\cdot x^{(j)})^p\n",
        "$$\n",
        "$c$ es un escalar y $k$ es un número natural"
      ],
      "metadata": {
        "id": "Rlu1ml1BNLzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KernelPCA_:\n",
        "    def __init__(self, n_components=2, c=1, k=2):\n",
        "        self.n_components = n_components\n",
        "        self.c = c\n",
        "        self.k = k\n",
        "        self.alphas_ = None\n",
        "        self.lambdas_ = None\n",
        "        self.X_fit_ = None\n",
        "        self.K_fit_ = None\n",
        "\n",
        "    def _kernel(self, X, Y):\n",
        "        \"\"\" Kernel polinomial personalizado \"\"\"\n",
        "        dot = np.dot(X, Y.T)\n",
        "        K = np.zeros(dot.shape)\n",
        "        for p in range(self.k + 1):\n",
        "            K += (self.c * dot) ** p\n",
        "        return K\n",
        "\n",
        "    def _center_kernel(self, K):\n",
        "        \"\"\" Centra la matriz de kernel \"\"\"\n",
        "        N = K.shape[0]\n",
        "        one_n = np.ones((N, N)) / N\n",
        "        K_centered = K - one_n @ K - K @ one_n + one_n @ K @ one_n\n",
        "        return K_centered\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\" Ajusta Kernel PCA \"\"\"\n",
        "        self.X_fit_ = X\n",
        "        K = self._kernel(X, X)\n",
        "        K_centered = self._center_kernel(K)\n",
        "        self.K_fit_ = K_centered\n",
        "\n",
        "\n",
        "        eigvals, eigvecs = np.linalg.eigh(K_centered)\n",
        "\n",
        "\n",
        "        idx = np.argsort(eigvals)[::-1]\n",
        "        eigvals = eigvals[idx]\n",
        "        eigvecs = eigvecs[:, idx]\n",
        "\n",
        "\n",
        "        self.lambdas_ = eigvals[:self.n_components]\n",
        "        self.alphas_ = eigvecs[:, :self.n_components]\n",
        "\n",
        "\n",
        "        self.alphas_ = self.alphas_ / np.sqrt(self.lambdas_)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\" Proyecta nuevos datos al espacio del kernel \"\"\"\n",
        "        K = self._kernel(X, self.X_fit_)\n",
        "        K_centered = K - np.mean(self.K_fit_, axis=0)  # centrar respecto al entrenamiento\n",
        "        return np.dot(K_centered, self.alphas_)\n"
      ],
      "metadata": {
        "id": "Ir5yMhQ9NOSW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Genera un conjunto de datos de *medias lunas* con 200 muestras, ruido=0.05, replicabilidad=42; utiliza los valores $[1,5,10,15]$ para los parámetros $c$ y $k$ de tu función $KernelPCA$ y determina la mejor combinación; explica tu elección**"
      ],
      "metadata": {
        "id": "YyYetW_ENQ0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = make_moons(n_samples=200, noise=0.05, random_state=42)\n",
        "\n",
        "\n",
        "param_values = [1, 5, 10, 15]\n",
        "\n",
        "\n",
        "results = {}\n",
        "\n",
        "for c in param_values:\n",
        "    for k in param_values:\n",
        "        kpca = KernelPCA_(n_components=2, c=c, k=k)\n",
        "        kpca.fit(X)\n",
        "        X_kpca = kpca.transform(X)\n",
        "\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_kpca, y, test_size=0.3, random_state=42)\n",
        "        clf = LogisticRegression()\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "        results[(c, k)] = acc\n",
        "\n",
        "\n",
        "best_params = max(results, key=results.get)\n",
        "\n",
        "\n",
        "print(f\"mejor: c = {best_params[0]}, k = {best_params[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuhkCur-NR8I",
        "outputId": "c15c5d6a-f1a9-42d1-d094-47392540cdb6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mejor: c = 10, k = 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Genera un conjunto de datos de *círculos concéntricos* con 200 muestras, ruido=0.1, factor=0.5 y replicabilidad=42; utiliza los valores $[1,5,10,15]$ para los parámetros $c$ y $k$ de tu función $KernelPCA$ y determina la mejor combinación; explica tu elección**"
      ],
      "metadata": {
        "id": "8KHVJVjLNoCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X, y = make_circles(n_samples=200, noise=0.1, factor=0.5, random_state=42)\n",
        "\n",
        "\n",
        "param_values = [1, 5, 10, 15]\n",
        "results = {}\n",
        "\n",
        "\n",
        "for c in param_values:\n",
        "    for k in param_values:\n",
        "        kpca = KernelPCA_(n_components=2, c=c, k=k)\n",
        "        kpca.fit(X)\n",
        "        X_kpca = kpca.transform(X)\n",
        "\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_kpca, y, test_size=0.3, random_state=42)\n",
        "        clf = LogisticRegression()\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "        results[(c, k)] = acc\n",
        "\n",
        "\n",
        "best_params = max(results, key=results.get)\n",
        "best_acc = results[best_params]\n",
        "\n",
        "print(f\"mejor: c = {best_params[0]}, k = {best_params[1]}\")\n",
        "print(f\"niveñ de exactitud: {best_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0qx-rxENn3m",
        "outputId": "39a843c9-24da-408e-f4ff-eec1c991922e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mejor: c = 5, k = 10\n",
            "niveñ de exactitud: 0.8667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Elige dos estimadores y demuestra que definen algoritmos escalables** (5p)\n",
        "$$\n",
        "\\underset{p\\times1}{\\overline{\\mathbf{x}}}=n^{-1}\\left[\\sum_{i=1}^{n}x_{i,1},\\ldots,\\sum_{i=1}^{n}x_{i,p}\\right]^{T}\n",
        "$$\n",
        "$$\n",
        "\\hat{\\sigma}_{j}^{2}=n^{-1}\\sum_{i=1}^{n}x_{i,j}^{2}-\\overline{x}_{j}^{2}\n",
        "$$\n",
        "$$\n",
        "\\hat{\\sigma}_{jk}=n^{-1}\\sum_{i=1}^{n}x_{i,j}x_{i,k}-\\overline{x}_{j}\\overline{x}_{k}\n",
        "$$"
      ],
      "metadata": {
        "id": "B81ICCKSOqJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demostración Matemática de Escalabilidad\n",
        "\n",
        "## 1. Vector de Medias Muestrales\n",
        "\n",
        "### Definición:\n",
        "$$\n",
        "\\overline{\\mathbf{x}}^{(n)} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{x}_i\n",
        "$$\n",
        "\n",
        "### Actualización Online:\n",
        "Sea:\n",
        "- $(n_{old})$: tamaño de muestra anterior\n",
        "- $(\\overline{\\mathbf{x}}_{old})$: media anterior\n",
        "- (m): nuevo lote de datos $(\\{\\mathbf{y}_1, \\ldots, \\mathbf{y}_m\\}$$)\n",
        "\n",
        "Entonces:\n",
        "$$\n",
        "n_{new} = n_{old} + m\n",
        "$$\n",
        "$$\n",
        "\\overline{\\mathbf{x}}_{new} = \\frac{1}{n_{new}} \\left( \\sum_{i=1}^{n_{old}} \\mathbf{x}_i + \\sum_{j=1}^{m} \\mathbf{y}_j \\right)\n",
        "$$\n",
        "\n",
        "Sustituyendo:\n",
        "$$\n",
        "\\sum_{i=1}^{n_{old}} \\mathbf{x}_i = n_{old} \\cdot \\overline{\\mathbf{x}}_{old}\n",
        "$$\n",
        "$$\n",
        "\\overline{\\mathbf{x}}_{new} = \\frac{1}{n_{new}} \\left( n_{old} \\cdot \\overline{\\mathbf{x}}_{old} + \\sum_{j=1}^{m} \\mathbf{y}_j \\right)\n",
        "$$\n",
        "\n",
        "### Complejidad:\n",
        "- Cálculo del nuevo lote: $(O(mp))$\n",
        "- Combinación: $(O(p))$\n",
        "- Memoria: $(O(p))$ (solo guardar $(n_{old}))$ y $(overline{\\mathbf{x}}_{old}))$\n",
        "- No depende de $(n_{old})$, solo del nuevo lote (m)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Varianza Muestral\n",
        "\n",
        "### Definición:\n",
        "$$\n",
        "\\hat{\\sigma}_j^2 = \\frac{1}{n} \\sum_{i=1}^{n} x_{i,j}^2 - \\bar{x}_j^2\n",
        "$$\n",
        "\n",
        "### Formulación equivalente:\n",
        "$$\n",
        "\\hat{\\sigma}_j^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_{i,j} - \\bar{x}_j)^2\n",
        "$$\n",
        "\n",
        "### Algoritmo de actualización (Welford):\n",
        "Definimos estadísticos suficientes:\n",
        "1. $(n)$: contador de muestras\n",
        "2. $(\\bar{x}_j)$: media acumulada\n",
        "3. $(M2_j)$: suma de cuadrados de diferencias\n",
        "\n",
        "Para cada nueva observación $(x)$:\n",
        "$$\n",
        "n_{new} = n_{old} + 1\n",
        "$$\n",
        "$$\n",
        "\\delta = x - \\bar{x}_{old}\n",
        "$$\n",
        "$$\n",
        "\\bar{x}_{new} = \\bar{x}_{old} + \\frac{\\delta}{n_{new}}\n",
        "$$\n",
        "$$\n",
        "M2_{new} = M2_{old} + \\delta \\cdot (x - \\bar{x}_{new})\n",
        "$$\n",
        "\n",
        "### Para lotes de tamaño $(m)$:\n",
        "Sea $(\\bar{x}_{batch})$ la media del lote y $(M2_{batch})$ su suma de cuadrados centrada.\n",
        "\n",
        "$$\n",
        "n_{new} = n_{old} + m\n",
        "$$\n",
        "$$\n",
        "\\delta = \\bar{x}_{batch} - \\bar{x}_{old}\n",
        "$$\n",
        "$$\n",
        "\\bar{x}_{new} = \\bar{x}_{old} + \\delta \\cdot \\frac{m}{n_{new}}\n",
        "$$\n",
        "$$\n",
        "M2_{new} = M2_{old} + M2_{batch} + \\delta^2 \\cdot \\frac{n_{old} \\cdot m}{n_{new}}\n",
        "$$\n",
        "\n",
        "Finalmente:\n",
        "$$\n",
        "\\hat{\\sigma}_j^2 = \\frac{M2_{new}}{n_{new}}\n",
        "$$\n",
        "\n",
        "### Complejidad:\n",
        "- Por lote: $(O(m))$ para cada variable\n",
        "- Memoria: $(O(p))$ (3 valores por variable: $(n)$, $(\\bar{x}_j)$, $(M2_j)$)\n",
        "- Escalabilidad lineal con nuevos datos\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Covarianza Muestral\n",
        "\n",
        "### Definición:\n",
        "$$\n",
        "\\hat{\\sigma}_{jk} = \\frac{1}{n} \\sum_{i=1}^{n} x_{i,j} x_{i,k} - \\bar{x}_j \\bar{x}_k\n",
        "$$\n",
        "\n",
        "### Estadísticos suficientes:\n",
        "1. $(n)$: contador\n",
        "2. $(\\bar{x}_j)$, $(\\bar{x}_k)$: medias\n",
        "3. $(S_{jk} = \\sum_{i=1}^{n} x_{i,j} x_{i,k})$: suma de productos\n",
        "\n",
        "### Actualización para una observación $((x_j, x_k))$:\n",
        "$$\n",
        "n_{new} = n_{old} + 1\n",
        "$$\n",
        "$$\n",
        "\\bar{x}_{j,new} = \\bar{x}_{j,old} + \\frac{x_j - \\bar{x}_{j,old}}{n_{new}}\n",
        "$$\n",
        "$$\n",
        "\\bar{x}_{k,new} = \\bar{x}_{k,old} + \\frac{x_k - \\bar{x}_{k,old}}{n_{new}}\n",
        "$$\n",
        "$$\n",
        "S_{jk,new} = S_{jk,old} + x_j x_k\n",
        "$$\n",
        "\n",
        "### Para lotes:\n",
        "Sea $(S_{jk}^{batch} = \\sum_{i=1}^{m} x_{i,j}^{batch} x_{i,k}^{batch})$\n",
        "\n",
        "$$\n",
        "n_{new} = n_{old} + m\n",
        "$$\n",
        "$$\n",
        "\\bar{x}_{j,new} = \\frac{n_{old} \\cdot \\bar{x}_{j,old} + m \\cdot \\bar{x}_{j}^{batch}}{n_{new}}\n",
        "$$\n",
        "$$\n",
        "S_{jk,new} = S_{jk,old} + S_{jk}^{batch}\n",
        "$$\n",
        "\n",
        "La covarianza se calcula bajo demanda:\n",
        "$$\n",
        "\\hat{\\sigma}_{jk} = \\frac{S_{jk,new}}{n_{new}} - \\bar{x}_{j,new} \\cdot \\bar{x}_{k,new}\n",
        "$$\n",
        "\n",
        "### Complejidad:\n",
        "- Calcular $(S_{jk}^{batch})$: $(O(m))$ por par de variables\n",
        "- Memoria:\n",
        "  - Versión completa: $(O(p^2))$ (matriz $(S)$)\n",
        "  - Versión por pares: \\(O(1)\\) por par\n",
        "- Actualización constante con nuevos datos"
      ],
      "metadata": {
        "id": "KAJZgpEsOorR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Escribe una función que obtenga *desde cero* la matriz de momentos aumentada a partir de un conjunto de vectores dados como arreglo de *numpy* de $[n\\_filas, m\\_columnas]$** (15p)"
      ],
      "metadata": {
        "id": "GkgYslAVRZ3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def matriz_momentos_aumentada(X):\n",
        "    X = X.astype(float)\n",
        "\n",
        "\n",
        "    n, m = X.shape\n",
        "\n",
        "\n",
        "    mu = np.mean(X, axis=0)\n",
        "\n",
        "    moments = (X.T @ X) / n\n",
        "\n",
        "    M = np.zeros((m+1, m+1))\n",
        "\n",
        "\n",
        "    M[0, 1:] = mu\n",
        "\n",
        "    M[1:, 0] = mu\n",
        "\n",
        "\n",
        "    M[1:, 1:] = moments\n",
        "\n",
        "    return M"
      ],
      "metadata": {
        "id": "a0XFa6QHRbR-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Genera una matriz de $(4\\times3)$ con números pseudoaleatorios enteros en el rango $[0,10]$ utilizando un generador de *numpy* con semilla inicializada a 42**\n"
      ],
      "metadata": {
        "id": "nZWYHiJgReA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "rng = np.random.default_rng(seed=42)\n",
        "\n",
        "\n",
        "A = rng.integers(low=0, high=11, size=(4, 3))\n",
        "\n",
        "\n",
        "display(A)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "1kIbX8lqRaOa",
        "outputId": "7d8fa6f5-3643-41c4-a3af-c189e41fdc70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 0,  8,  7],\n",
              "       [ 4,  4,  9],\n",
              "       [ 0,  7,  2],\n",
              "       [ 1,  5, 10]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Aplica tu función de matriz de momentos aumentada a la matriz generada en el punto anterior**"
      ],
      "metadata": {
        "id": "EFrUczwkRkaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "amm = matriz_momentos_aumentada(A)\n",
        "\n",
        "\n",
        "display(amm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "3Qoz6TBFRmCu",
        "outputId": "f65e594e-e17c-4911-edea-6817e4da0768"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 0.  ,  1.25,  6.  ,  7.  ],\n",
              "       [ 1.25,  4.25,  5.25, 11.5 ],\n",
              "       [ 6.  ,  5.25, 38.5 , 39.  ],\n",
              "       [ 7.  , 11.5 , 39.  , 58.5 ]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Obtén las expresiones para determinar los intervalos de contenedores para histogramas bidimensionales en función del número de contenedores:** (5p)"
      ],
      "metadata": {
        "id": "1zY_0Q0-RqC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para construir un histograma 2D basado en un número predefinido de contenedores (*bins*), definimos las siguientes variables:\n",
        "\n",
        "* **Rango de los datos en X:** $[x_{min}, x_{max}]$\n",
        "* **Rango de los datos en Y:** $[y_{min}, y_{max}]$\n",
        "* **Número de contenedores deseados:** $k_x$ (para el eje X) y $k_y$ (para el eje Y).\n",
        "\n",
        "#### 1. Cálculo del Ancho de los Intervalos ($\\Delta$)\n",
        "El primer paso es determinar la amplitud de cada contenedor dividiendo el rango total por el número de bins:\n",
        "\n",
        "$$\\Delta x = \\frac{x_{max} - x_{min}}{k_x}$$\n",
        "\n",
        "$$\\Delta y = \\frac{y_{max} - y_{min}}{k_y}$$\n",
        "\n",
        "#### 2. Expresión de los Límites (Bordes de los contenedores)\n",
        "Los intervalos se definen mediante sus límites (bordes). La secuencia de bordes se genera sumando múltiplos del ancho al valor mínimo.\n",
        "\n",
        "**Para el eje X:**\n",
        "El $i$-ésimo borde, denotado como $e_{x,i}$, se calcula así:\n",
        "$$e_{x,i} = x_{min} + i \\cdot \\Delta x \\quad \\text{para } i = 0, 1, ..., k_x$$\n",
        "\n",
        "**Para el eje Y:**\n",
        "El $j$-ésimo borde, denotado como $e_{y,j}$, se calcula así:\n",
        "$$e_{y,j} = y_{min} + j \\cdot \\Delta y \\quad \\text{para } j = 0, 1, ..., k_y$$\n",
        "\n",
        "#### 3. Definición del Contenedor\n",
        "Un contenedor (bin) específico en la posición $(i, j)$ de la cuadrícula cubre el área rectangular definida por la intersección de los intervalos actuales y los siguientes:\n",
        "\n",
        "$$\\text{Bin}_{i,j} = [e_{x,i}, \\ e_{x,i+1}) \\times [e_{y,j}, \\ e_{y,j+1})$$"
      ],
      "metadata": {
        "id": "Hnmy_ArjRqzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) ¿Tus expresiones representan una estadística asociativa?**"
      ],
      "metadata": {
        "id": "5Zt7sPvJSjdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) ¿Tus expresiones representan una estadística asociativa?\n",
        "\n",
        "**Respuesta: No.**\n",
        "\n",
        "**Justificación:**\n",
        "\n",
        "1.  **Naturaleza de las expresiones:** Las fórmulas para determinar el ancho ($\\Delta$) y los límites de los intervalos son expresiones de **discretización** y partición geométrica. Se basan en estadísticos de **orden** (Mínimo y Máximo) y de **dispersión** (el Rango), calculados para cada variable de forma independiente.\n",
        "\n",
        "2.  **Diferencia con la Asociación:** Una estadística asociativa (como la covarianza o el coeficiente de correlación) debe cuantificar la dependencia o relación entre dos variables. Las expresiones de los intervalos no miden esta relación, solo definen la estructura de la cuadrícula.\n",
        "\n"
      ],
      "metadata": {
        "id": "05qJUaFlTMbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Genera una matriz de números pseudoaleatorios enteros en el rango $[0,10]$ de $(16\\times4)$ utilizando un generador de *numpy* con semilla inicializada a 42** (15p)\n",
        "\n",
        "**a) Aplica tu implementación de la pregunta 9 a esta matriz**"
      ],
      "metadata": {
        "id": "qE5Gaw2cTSEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rng = np.random.default_rng(seed=42)\n",
        "\n",
        "\n",
        "A_ = rng.integers(low=0, high=11, size=(16, 4))\n",
        "\n",
        "\n",
        "display(A_)\n",
        "\n",
        "amm_ = matriz_momentos_aumentada(A_)\n",
        "\n",
        "display(amm_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "uNwSHdp2TRuX",
        "outputId": "2895c2a4-a870-4421-f810-0e38a61b47be"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 0,  8,  7,  4],\n",
              "       [ 4,  9,  0,  7],\n",
              "       [ 2,  1,  5, 10],\n",
              "       [ 8,  8,  7,  8],\n",
              "       [ 5,  1,  9,  4],\n",
              "       [ 5,  4,  2, 10],\n",
              "       [ 8,  7,  4,  9],\n",
              "       [ 5,  4,  4,  2],\n",
              "       [ 1,  6,  9,  0],\n",
              "       [ 9,  9,  3,  6],\n",
              "       [ 1,  8,  7,  3],\n",
              "       [ 0, 10,  4,  9],\n",
              "       [ 7,  8,  8,  2],\n",
              "       [ 4,  5,  5,  0],\n",
              "       [ 6,  1,  8,  7],\n",
              "       [10,  8,  4, 10]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[ 0.    ,  4.6875,  6.0625,  5.375 ,  5.6875],\n",
              "       [ 4.6875, 31.6875, 28.75  , 23.75  , 29.8125],\n",
              "       [ 6.0625, 28.75  , 45.4375, 30.25  , 34.6875],\n",
              "       [ 5.375 , 23.75  , 30.25  , 35.25  , 26.3125],\n",
              "       [ 5.6875, 29.8125, 34.6875, 26.3125, 44.3125]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b) Simula el cálculo de la matriz de momentos aumentada en un entorno *Map-Reduce* con 4 nodos secundarios: el nodo 1 recibe el primer bloque de datos y así sucesivamente**"
      ],
      "metadata": {
        "id": "7FSoME2GTh3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "rng = np.random.default_rng(seed=42)\n",
        "A_ = rng.integers(low=0, high=11, size=(16, 4))\n",
        "\n",
        "print(\"--- DATOS ORIGINALES (A_) ---\")\n",
        "print(A_)\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "chunks = np.array_split(A_, 4)\n",
        "\n",
        "\n",
        "map_results = []\n",
        "\n",
        "\n",
        "for i, chunk in enumerate(chunks):\n",
        "    node_id = i + 1\n",
        "\n",
        "    ones_col = np.ones((chunk.shape[0], 1))\n",
        "    chunk_aug = np.hstack([ones_col, chunk])\n",
        "\n",
        "    local_moment_matrix = chunk_aug.T @ chunk_aug\n",
        "\n",
        "    map_results.append(local_moment_matrix)\n",
        "\n",
        "    print(f\"Node {node_id} procesó filas {i*4} a {(i*4)+3}\")\n",
        "    print(f\"Matriz Local (Node {node_id}):\\n{local_moment_matrix}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "reduced_result = np.zeros_like(map_results[0])\n",
        "\n",
        "for res in map_results:\n",
        "    reduced_result += res\n",
        "\n",
        "print(\"Matriz de Momentos Aumentada Final:\")\n",
        "print(reduced_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkffLkNNSkkB",
        "outputId": "883a0363-b061-4334-e99c-3b853cff9cc0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DATOS ORIGINALES (A_) ---\n",
            "[[ 0  8  7  4]\n",
            " [ 4  9  0  7]\n",
            " [ 2  1  5 10]\n",
            " [ 8  8  7  8]\n",
            " [ 5  1  9  4]\n",
            " [ 5  4  2 10]\n",
            " [ 8  7  4  9]\n",
            " [ 5  4  4  2]\n",
            " [ 1  6  9  0]\n",
            " [ 9  9  3  6]\n",
            " [ 1  8  7  3]\n",
            " [ 0 10  4  9]\n",
            " [ 7  8  8  2]\n",
            " [ 4  5  5  0]\n",
            " [ 6  1  8  7]\n",
            " [10  8  4 10]]\n",
            "\n",
            "========================================\n",
            "\n",
            "Node 1 procesó filas 0 a 3\n",
            "Matriz Local (Node 1):\n",
            "[[  4.  14.  26.  19.  29.]\n",
            " [ 14.  84. 102.  66. 112.]\n",
            " [ 26. 102. 210. 117. 169.]\n",
            " [ 19.  66. 117. 123. 134.]\n",
            " [ 29. 112. 169. 134. 229.]]\n",
            "\n",
            "Node 2 procesó filas 4 a 7\n",
            "Matriz Local (Node 2):\n",
            "[[  4.  23.  16.  19.  25.]\n",
            " [ 23. 139. 101. 107. 152.]\n",
            " [ 16. 101.  82.  61. 115.]\n",
            " [ 19. 107.  61. 117. 100.]\n",
            " [ 25. 152. 115. 100. 201.]]\n",
            "\n",
            "Node 3 procesó filas 8 a 11\n",
            "Matriz Local (Node 3):\n",
            "[[  4.  11.  33.  23.  18.]\n",
            " [ 11.  83.  95.  43.  57.]\n",
            " [ 33.  95. 281. 177. 168.]\n",
            " [ 23.  43. 177. 155.  75.]\n",
            " [ 18.  57. 168.  75. 126.]]\n",
            "\n",
            "Node 4 procesó filas 12 a 15\n",
            "Matriz Local (Node 4):\n",
            "[[  4.  27.  22.  25.  19.]\n",
            " [ 27. 201. 162. 164. 156.]\n",
            " [ 22. 162. 154. 129. 103.]\n",
            " [ 25. 164. 129. 169. 112.]\n",
            " [ 19. 156. 103. 112. 153.]]\n",
            "\n",
            "Matriz de Momentos Aumentada Final:\n",
            "[[ 16.  75.  97.  86.  91.]\n",
            " [ 75. 507. 460. 380. 477.]\n",
            " [ 97. 460. 727. 484. 555.]\n",
            " [ 86. 380. 484. 564. 421.]\n",
            " [ 91. 477. 555. 421. 709.]]\n"
          ]
        }
      ]
    }
  ]
}